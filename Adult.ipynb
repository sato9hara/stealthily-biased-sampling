{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## This notebook contains a sample code for the Adult data experiment in Section 5.3.\n",
    "\n",
    "Before running the code, please check README.md and install LEMON.\n",
    "\n",
    "* Please use an appropriate machine to run this notebook.\n",
    "    * This notebook runs min-cost flow solver in 10-parallel."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegressionCV\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import stealth_sampling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split data to bins (s, y) = (1, 1), (1, 0), (0, 1), (0, 0)\n",
    "def split_to_four(X, S, Y):\n",
    "    Z = np.c_[X, S, Y]\n",
    "    Z_pos_pos = Z[np.logical_and(S, Y), :]\n",
    "    Z_pos_neg = Z[np.logical_and(S, np.logical_not(Y)), :]\n",
    "    Z_neg_pos = Z[np.logical_and(np.logical_not(S), Y), :]\n",
    "    Z_neg_neg = Z[np.logical_and(np.logical_not(S), np.logical_not(Y)), :]\n",
    "    Z = [Z_pos_pos, Z_pos_neg, Z_neg_pos, Z_neg_neg]\n",
    "    return Z\n",
    "\n",
    "# compute demographic parity\n",
    "def demographic_parity(W):\n",
    "    p_pos = np.mean(np.concatenate(W[:2]))\n",
    "    p_neg = np.mean(np.concatenate(W[2:]))\n",
    "    return np.abs(p_pos - p_neg)\n",
    "\n",
    "# compute the sampling size from each bin\n",
    "def computeK(Z, Nsample, sampled_spos, sampled_ypos):\n",
    "    Kpp = Nsample*sampled_spos*sampled_ypos[0]\n",
    "    Kpn = Nsample*sampled_spos*(1-sampled_ypos[0])\n",
    "    Knp = Nsample*(1-sampled_spos)*sampled_ypos[1]\n",
    "    Knn = Nsample*(1-sampled_spos)*(1-sampled_ypos[1])\n",
    "    K = [Kpp, Kpn, Knp, Knn]\n",
    "    kratio = min([min(1, z.shape[0]/k) for (z, k) in zip(Z, K)])\n",
    "    Kpp = int(np.floor(Nsample*kratio*sampled_spos*sampled_ypos[0]))\n",
    "    Kpn = int(np.floor(Nsample*kratio*sampled_spos*(1-sampled_ypos[0])))\n",
    "    Knp = int(np.floor(Nsample*kratio*(1-sampled_spos)*sampled_ypos[1]))\n",
    "    Knn = int(np.floor(Nsample*kratio*(1-sampled_spos)*(1-sampled_ypos[1])))\n",
    "    K = [max([k, 1]) for k in [Kpp, Kpn, Knp, Knn]]\n",
    "    return K\n",
    "\n",
    "# case-contrl sampling\n",
    "def case_control_sampling(X, K):\n",
    "    q = [(K[i]/sum(K)) * np.ones(x.shape[0]) / x.shape[0] for i, x in enumerate(X)]\n",
    "    return q\n",
    "\n",
    "# compute wasserstein distance w/ boostrap\n",
    "def compute_wasserstein(X1, S1, X2, S2, n, num_sample=5, num_process=10, seed=0):\n",
    "    dx = stealth_sampling.compute_wasserstein_bootstrap(X1, X2, n, path='./', prefix='adult', num_sample=num_sample, num_process=num_process, seed=seed, timeout=60)\n",
    "    dx_s1 = stealth_sampling.compute_wasserstein_bootstrap(X1[S1>0.5, :], X2[S2>0.5, :], n, path='./', prefix='adult', num_sample=num_sample, num_process=num_process, seed=seed+1, timeout=60)\n",
    "    dx_s0 = stealth_sampling.compute_wasserstein_bootstrap(X1[S1<0.5, :], X2[S2<0.5, :], n, path='./', prefix='adult', num_sample=num_sample, num_process=num_process, seed=seed+2, timeout=60)\n",
    "    return dx, dx_s1, dx_s0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fetch data and preprocess\n",
    "We modefied [https://www.kaggle.com/kost13/us-income-logistic-regression/notebook]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fetch data\n",
    "url1 = 'https://archive.ics.uci.edu/ml/machine-learning-databases/adult/adult.data'\n",
    "url2 = 'https://archive.ics.uci.edu/ml/machine-learning-databases/adult/adult.test'\n",
    "columns = ['Age','Workclass','fnlgwt','Education','Education num','Marital Status',\n",
    "           'Occupation','Relationship','Race','Sex','Capital Gain','Capital Loss',\n",
    "           'Hours/Week','Native country','Income']\n",
    "df1 = pd.read_table(url1, sep=',', header=None, names=columns)\n",
    "df2 = pd.read_table(url2, sep=',', skiprows=1, header=None, names=columns)\n",
    "df = pd.concat([df1, df2], axis=0, ignore_index=True, sort=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# preprocessing\n",
    "def primary(x):\n",
    "    if x in [' 1st-4th', ' 5th-6th', ' 7th-8th', ' 9th', ' 10th', ' 11th', ' 12th']:\n",
    "        return ' Primary'\n",
    "    else:\n",
    "        return x\n",
    "    \n",
    "def native(country):\n",
    "    if country in [' United-States', ' Cuba', ' 0']:\n",
    "        return 'US'\n",
    "    elif country in [' England', ' Germany', ' Canada', ' Italy', ' France', ' Greece', ' Philippines']:\n",
    "        return 'Western'\n",
    "    elif country in [' Mexico', ' Puerto-Rico', ' Honduras', ' Jamaica', ' Columbia', ' Laos', ' Portugal', ' Haiti',\n",
    "                     ' Dominican-Republic', ' El-Salvador', ' Guatemala', ' Peru', \n",
    "                     ' Trinadad&Tobago', ' Outlying-US(Guam-USVI-etc)', ' Nicaragua', ' Vietnam', ' Holand-Netherlands' ]:\n",
    "        return 'Poor' # no offence\n",
    "    elif country in [' India', ' Iran', ' Cambodia', ' Taiwan', ' Japan', ' Yugoslavia', ' China', ' Hong']:\n",
    "        return 'Eastern'\n",
    "    elif country in [' South', ' Poland', ' Ireland', ' Hungary', ' Scotland', ' Thailand', ' Ecuador']:\n",
    "        return 'Poland team'\n",
    "    \n",
    "    else: \n",
    "        return country\n",
    "\n",
    "df.replace(' ?', np.nan, inplace=True)\n",
    "df['Income'] = df['Income'].apply(lambda x: 1 if x in (' >50K', ' >50K.') else 0)\n",
    "df['Workclass'].fillna(' 0', inplace=True)\n",
    "df['Workclass'].replace(' Without-pay', ' Never-worked', inplace=True)\n",
    "df['fnlgwt'] = df['fnlgwt'].apply(lambda x: np.log1p(x))\n",
    "df['Education'] = df['Education'].apply(primary)\n",
    "df['Marital Status'].replace(' Married-AF-spouse', ' Married-civ-spouse', inplace=True)\n",
    "df['Occupation'].fillna(' 0', inplace=True)\n",
    "df['Occupation'].replace(' Armed-Forces', ' 0', inplace=True)\n",
    "df['Native country'].fillna(' 0', inplace=True)\n",
    "df['Native country'] = df['Native country'].apply(native)\n",
    "categorical_features = df.select_dtypes(include=['object']).axes[1]\n",
    "for col in categorical_features:\n",
    "    df = pd.concat([df, pd.get_dummies(df[col], prefix=col, prefix_sep=':')], axis=1)\n",
    "    df.drop(col, axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# parameter settings for data\n",
    "seed = 0                    # random seed\n",
    "Ntr = 10000                 # number of samples for training\n",
    "Nte = 20000                 # number of samples for testing\n",
    "\n",
    "# parameter settings for model\n",
    "classifier = 'LogReg'\n",
    "#classifier = 'Forest'\n",
    "\n",
    "# parameter settings for sampling\n",
    "Nsample = 2000              # number of data to sample\n",
    "sampled_ypos = [0.2, 0.2]   # the ratio of positive decisions '\\alpha' in sampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample_and_evaluate(df, Ntr=10000, Nte=20000, Nsample=2000, classifier='LogReg', sampled_ypos=[0.2, 0.2], seed=0):\n",
    "    \n",
    "    # split data\n",
    "    df_train, df_ref = train_test_split(df, test_size=1.0-Ntr/df.shape[0], random_state=seed)\n",
    "    df_test, df_ref = train_test_split(df_ref, test_size=1.0-Nte/df_ref.shape[0], random_state=seed)\n",
    "    \n",
    "    # df to numpy array\n",
    "    Xtr = df_train.drop(['Income', 'Sex: Male', 'Sex: Female'], axis=1).values\n",
    "    Str = df_train['Sex: Male'].values\n",
    "    Ytr = df_train['Income'].values\n",
    "    Xte = df_test.drop(['Income', 'Sex: Male', 'Sex: Female'], axis=1).values\n",
    "    Ste = df_test['Sex: Male'].values\n",
    "    Yte = df_test['Income'].values\n",
    "    Xref = df_ref.drop(['Income', 'Sex: Male', 'Sex: Female'], axis=1).values\n",
    "    Sref = df_ref['Sex: Male'].values\n",
    "    Yref = df_ref['Income'].values\n",
    "    \n",
    "    # normalize\n",
    "    scaler = StandardScaler()\n",
    "    scaler.fit(Xtr)\n",
    "    Xtr = scaler.transform(Xtr)\n",
    "    Xte = scaler.transform(Xte)\n",
    "    Xref = scaler.transform(Xref)\n",
    "    \n",
    "    # fit model\n",
    "    if classifier == 'LogReg':\n",
    "        model = LogisticRegressionCV(cv=3)\n",
    "    elif classifier == 'Forest':\n",
    "        model = RandomForestClassifier(n_estimators=100, random_state=seed)\n",
    "    model.fit(np.c_[Xtr, Str], Ytr)\n",
    "    Ttr = model.predict(np.c_[Xtr, Str])\n",
    "    Tte = model.predict(np.c_[Xte, Ste])\n",
    "    acc = 1.0 - np.mean(np.abs(Yte - Tte))\n",
    "    Z = split_to_four(Xte, Ste, Tte)\n",
    "    parity = demographic_parity([z[:, -1] for z in Z])\n",
    "    \n",
    "    # wasserstein distance between te and ref\n",
    "    np.random.seed(seed)\n",
    "    idx = np.random.permutation(Xte.shape[0])[:Nsample]\n",
    "    dx, dx_s1, dx_s0 = compute_wasserstein(Xte[idx, :], Ste[idx], Xref, Sref, 2000, num_sample=3, num_process=10, seed=seed)\n",
    "    \n",
    "    # sampling\n",
    "    results = [[acc, parity, dx, dx_s1, dx_s0]]\n",
    "    sampled_spos = np.mean(Ste)\n",
    "    K = computeK(Z, Nsample, sampled_spos, sampled_ypos)\n",
    "    for i, sampling in enumerate(['case-control', 'stealth']):\n",
    "        print('%s: sampling ...' % (sampling,), end='')\n",
    "        np.random.seed(seed+i)\n",
    "        if sampling == 'case-control':\n",
    "            p = case_control_sampling([z[:, :-1] for z in Z], K)\n",
    "        elif sampling == 'stealth':\n",
    "            p = stealth_sampling.stealth_sampling_bootstrap([z[:, :-1] for z in Z], K, path='./', prefix='adult', ratio=0.20, num_sample=3, num_process=10, timeout=60.0)\n",
    "        idx = np.random.choice(Nte, sum(K), p=np.concatenate(p), replace=False)\n",
    "        Xs = np.concatenate([z[:, :-2] for z in Z], axis=0)[idx, :]\n",
    "        Ss = np.concatenate([z[:, -2] for z in Z], axis=0)[idx]\n",
    "        Ts = np.concatenate([z[:, -1] for z in Z], axis=0)[idx]\n",
    "        print('done.')\n",
    "        \n",
    "        # demographic parity of the sampled data\n",
    "        print('%s: evaluating ...' % (sampling,), end='')\n",
    "        Zs = split_to_four(Xs, Ss, Ts)\n",
    "        parity = demographic_parity([z[:, -1] for z in Zs])\n",
    "        \n",
    "        # wasserstein disttance\n",
    "        dx, dx_s1, dx_s0 = compute_wasserstein(Xs, Ss, Xref, Sref, 2000, num_sample=3, num_process=10, seed=seed)\n",
    "        print('done.')\n",
    "        \n",
    "        results.append([np.nan, parity, dx, dx_s1, dx_s0])\n",
    "    return results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Experiment (One Run)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "case-control: sampling ...done.\n",
      "case-control: evaluating ...done.\n",
      "stealth: sampling ...done.\n",
      "stealth: evaluating ...done.\n"
     ]
    }
   ],
   "source": [
    "result = sample_and_evaluate(df, Ntr=Ntr, Nte=Nte, Nsample=Nsample, classifier=classifier, sampled_ypos=sampled_ypos, seed=seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result (alpha = 0.20, seed=0)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>DP</th>\n",
       "      <th>WD on Pr[x]</th>\n",
       "      <th>WD on Pr[x|s=1]</th>\n",
       "      <th>WD on Pr[x|s=0]</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Baseline</th>\n",
       "      <td>0.851</td>\n",
       "      <td>0.182413</td>\n",
       "      <td>22.163767</td>\n",
       "      <td>25.645400</td>\n",
       "      <td>35.042133</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Case-control</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.025077</td>\n",
       "      <td>23.906033</td>\n",
       "      <td>22.585533</td>\n",
       "      <td>37.954267</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Stealth</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.071191</td>\n",
       "      <td>23.639633</td>\n",
       "      <td>24.240400</td>\n",
       "      <td>36.165700</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              Accuracy        DP  WD on Pr[x]  WD on Pr[x|s=1]  \\\n",
       "Baseline         0.851  0.182413    22.163767        25.645400   \n",
       "Case-control       NaN  0.025077    23.906033        22.585533   \n",
       "Stealth            NaN  0.071191    23.639633        24.240400   \n",
       "\n",
       "              WD on Pr[x|s=0]  \n",
       "Baseline            35.042133  \n",
       "Case-control        37.954267  \n",
       "Stealth             36.165700  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame(result)\n",
    "df.index = ['Baseline', 'Case-control', 'Stealth']\n",
    "df.columns = ['Accuracy', 'DP', 'WD on Pr[x]', 'WD on Pr[x|s=1]', 'WD on Pr[x|s=0]']\n",
    "print('Result (alpha = %.2f, seed=%d)' % (sampled_ypos[0], seed))\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
